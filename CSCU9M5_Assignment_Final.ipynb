{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNn7uUi/z5jTR2JE5BZNcIy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashonet/CSCU9M5/blob/main/CSCU9M5_Assignment_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwrOOPqHMPSn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    RocCurveDisplay,\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "DATA_PATH = \"/content/forestfires_classification.csv\"\n",
        "\n",
        "\n",
        "# 1. DATA UNDERSTANDING\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(\"First rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nInfo:\")\n",
        "print(df.info())\n",
        "print(\"\\nDescribe numeric columns:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nTarget distribution (area):\")\n",
        "print(df[\"area\"].value_counts())\n",
        "\n",
        "print(\"\\nMonth distribution:\")\n",
        "print(df[\"month\"].value_counts())\n",
        "\n",
        "print(\"\\nDay distribution:\")\n",
        "print(df[\"day\"].value_counts())\n",
        "\n",
        "# Example quick plots for the poster\n",
        "plt.figure(figsize=(5, 4))\n",
        "df[\"area\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Target distribution (Burned area > 4%)\")\n",
        "plt.xlabel(\"area label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plot_target_distribution.png\", dpi=300)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "df[\"month\"].value_counts().sort_index().plot(kind=\"bar\")\n",
        "plt.title(\"Fires per Month\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plot_month_distribution.png\", dpi=300)\n",
        "\n",
        "\n",
        "# 2. DATA PREPARATION & VISUALISATION\n",
        "\n",
        "# Encode target as 0/1\n",
        "df[\"area_binary\"] = df[\"area\"].map({\"F\": 0, \"T\": 1})\n",
        "\n",
        "# Identify features & types\n",
        "feature_cols = [\n",
        "    \"X\", \"Y\", \"month\", \"day\", \"FFMC\", \"DMC\", \"DC\", \"ISI\",\n",
        "    \"temp\", \"RH\", \"wind\", \"rain\"\n",
        "]\n",
        "X = df[feature_cols]\n",
        "y = df[\"area_binary\"]\n",
        "\n",
        "numeric_features = [\"X\", \"Y\", \"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", \"rain\"]\n",
        "categorical_features = [\"month\", \"day\"]\n",
        "\n",
        "# Visualisation: correlation heatmap for numeric\n",
        "plt.figure(figsize=(8, 6))\n",
        "corr = df[numeric_features + [\"area_binary\"]].corr()\n",
        "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plot_correlation_heatmap.png\", dpi=300)\n",
        "\n",
        "# Example boxplot for one key feature\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.boxplot(x=\"area\", y=\"ISI\", data=df)\n",
        "plt.title(\"ISI vs Burned Area (T/F)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plot_boxplot_isi_area.png\", dpi=300)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "\n",
        "# 3. MODELLING APPROACH – PIPELINES DEFINITION\n",
        "\n",
        "# Preprocessor: OneHot for categorical, StandardScaler for numeric\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"scaler\", StandardScaler())]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
        ")\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Base models (no tuning yet)\n",
        "base_models = {\n",
        "    \"LogReg\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "}\n",
        "\n",
        "# 4. MODEL EXPERIMENTS & HYPERPARAMETER TUNING\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "for name, clf in base_models.items():\n",
        "    model = Pipeline(\n",
        "        steps=[(\"preprocess\", preprocess), (\"clf\", clf)]\n",
        "    )\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\")\n",
        "    cv_results.append(\n",
        "        {\n",
        "            \"model\": name,\n",
        "            \"mean_f1\": scores.mean(),\n",
        "            \"std_f1\": scores.std(),\n",
        "        }\n",
        "    )\n",
        "    print(f\"{name} CV F1: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
        "\n",
        "cv_df = pd.DataFrame(cv_results).sort_values(\"mean_f1\", ascending=False)\n",
        "print(\"\\nCross-validated F1 scores:\\n\", cv_df)\n",
        "\n",
        "cv_df.to_csv(\"cv_results_base_models.csv\", index=False)\n",
        "\n",
        "# ---- Hyperparameter grids for top models (example) ----\n",
        "param_grids = {\n",
        "    \"RandomForest\": {\n",
        "        \"clf__n_estimators\": [100, 200],\n",
        "        \"clf__max_depth\": [None, 5, 10],\n",
        "        \"clf__min_samples_split\": [2, 5],\n",
        "    },\n",
        "    \"GradientBoosting\": {\n",
        "        \"clf__n_estimators\": [100, 200],\n",
        "        \"clf__learning_rate\": [0.05, 0.1],\n",
        "        \"clf__max_depth\": [3, 5],\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"clf__C\": [0.1, 1, 10],\n",
        "        \"clf__kernel\": [\"rbf\", \"linear\"],\n",
        "        \"clf__gamma\": [\"scale\", \"auto\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for name in [\"RandomForest\", \"GradientBoosting\", \"SVM\"]:\n",
        "    print(f\"\\nGrid search for {name}...\")\n",
        "    pipe = Pipeline(\n",
        "        steps=[(\"preprocess\", preprocess), (\"clf\", base_models[name])]\n",
        "    )\n",
        "    grid = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid=param_grids[name],\n",
        "        cv=5,\n",
        "        scoring=\"f1\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Best F1 for {name}: {grid.best_score_:.3f}\")\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "    best_models[name] = grid\n",
        "\n",
        "# Pick the single best model based on CV F1\n",
        "best_name, best_grid = sorted(\n",
        "    best_models.items(), key=lambda kv: kv[1].best_score_, reverse=True\n",
        ")[0]\n",
        "\n",
        "print(f\"\\nSelected final model: {best_name}\")\n",
        "final_model = best_grid.best_estimator_"
      ]
    }
  ]
}